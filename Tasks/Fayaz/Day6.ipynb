{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day6.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpdBotkwv-fL"
      },
      "source": [
        "import tensorflow as tf \n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from keras.layers import GlobalAveragePooling2D, Dense\n",
        "from keras.layers import BatchNormalization, Dropout\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZp3moQsv__f",
        "outputId": "d37f0268-63af-4a17-8c2c-deb212e41cda"
      },
      "source": [
        "class_names=['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
        "\n",
        "(x_train,y_train),(x_test,y_test)=cifar10.load_data()\n",
        "\n",
        "x_train=x_train/255.0\n",
        "x_test=x_test/255.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNYl4HGjwB8P",
        "outputId": "a8d7978f-d3ee-4805-d9fa-375fd6519815"
      },
      "source": [
        "\n",
        "vgg19 = VGG19(weights=\"imagenet\", include_top=False, input_shape=(32,32, 3))\n",
        "vgg19.trainable = False"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n",
            "80150528/80134624 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sb9-KfywwF8A",
        "outputId": "7ce0c630-17c9-4021-b8c9-e7db710f9e4e"
      },
      "source": [
        "\n",
        "x = vgg19.output\n",
        "\n",
        "x = Dense(1000, activation='relu')(x)\n",
        "x = Dense(10, activation ='softmax')(x)\n",
        "\n",
        "model = Model(vgg19.input, x)\n",
        "model.compile(optimizer ='Adam', \n",
        "              loss =\"sparse_categorical_crossentropy\", \n",
        "              metrics =[\"sparse_categorical_accuracy\"]) \n",
        "\n",
        "model.fit(x_train,y_train, epochs = 5, validation_data = (x_test,y_test))\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(\"Test accuracy: {}\".format(test_accuracy))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 848s 542ms/step - loss: 1.3775 - sparse_categorical_accuracy: 0.1128 - val_loss: 1.3054 - val_sparse_categorical_accuracy: 0.1136\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 840s 538ms/step - loss: 1.2019 - sparse_categorical_accuracy: 0.1151 - val_loss: 1.1988 - val_sparse_categorical_accuracy: 0.1145\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 837s 536ms/step - loss: 1.1282 - sparse_categorical_accuracy: 0.1155 - val_loss: 1.1663 - val_sparse_categorical_accuracy: 0.1151\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 843s 540ms/step - loss: 1.0733 - sparse_categorical_accuracy: 0.1162 - val_loss: 1.1545 - val_sparse_categorical_accuracy: 0.1157\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 839s 537ms/step - loss: 1.0207 - sparse_categorical_accuracy: 0.1167 - val_loss: 1.1484 - val_sparse_categorical_accuracy: 0.1158\n",
            "313/313 [==============================] - 140s 446ms/step - loss: 1.1484 - sparse_categorical_accuracy: 0.1158\n",
            "Test accuracy: 0.11579263210296631\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cST_GV_WwIh7",
        "outputId": "bf60d3b1-df30-4b9a-c8fd-abb6287ba46e"
      },
      "source": [
        "res = ResNet50(weights ='imagenet', include_top = False, \n",
        "               input_shape =(32,32, 3)) \n",
        "res.trainable = False"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "94781440/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYvcgBFHwK81",
        "outputId": "ed4b6125-1105-48f4-b058-5b13b3ec212d"
      },
      "source": [
        "x= res.output\n",
        "\n",
        "x = Dense(1000, activation='relu')(x)\n",
        "x = Dense(10, activation ='softmax')(x)\n",
        "\n",
        "model = Model(res.input, x)\n",
        "model.compile(optimizer ='Adam', \n",
        "              loss =\"sparse_categorical_crossentropy\", \n",
        "              metrics =[\"sparse_categorical_accuracy\"]) \n",
        "# model.summary() \n",
        "model.fit(x_train,y_train, epochs = 5, validation_data = (x_test,y_test))\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(\"Test accuracy: {}\".format(test_accuracy))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 286s 181ms/step - loss: 2.0485 - sparse_categorical_accuracy: 0.1044 - val_loss: 1.9092 - val_sparse_categorical_accuracy: 0.1067\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 281s 180ms/step - loss: 1.8828 - sparse_categorical_accuracy: 0.1068 - val_loss: 1.7994 - val_sparse_categorical_accuracy: 0.1080\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 281s 180ms/step - loss: 1.8249 - sparse_categorical_accuracy: 0.1072 - val_loss: 1.7846 - val_sparse_categorical_accuracy: 0.1087\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 286s 183ms/step - loss: 1.8009 - sparse_categorical_accuracy: 0.1074 - val_loss: 1.7939 - val_sparse_categorical_accuracy: 0.1083\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 284s 182ms/step - loss: 1.7720 - sparse_categorical_accuracy: 0.1086 - val_loss: 1.7911 - val_sparse_categorical_accuracy: 0.1078\n",
            "313/313 [==============================] - 46s 146ms/step - loss: 1.7911 - sparse_categorical_accuracy: 0.1078\n",
            "Test accuracy: 0.10775495320558548\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3Fa1wC8wNb-",
        "outputId": "5399a03c-b8b5-473c-cfd6-00a210d3e347"
      },
      "source": [
        "\n",
        "mnet = MobileNetV2(weights ='imagenet', include_top = False, \n",
        "               input_shape =(32,32, 3)) \n",
        "mnet.trainable = False"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n",
            "9420800/9406464 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAv7xx6uwP3Y",
        "outputId": "d9fa68a0-c827-4fce-b2d5-1d31b9de7589"
      },
      "source": [
        "\n",
        "x = mnet.output\n",
        "\n",
        "x = Dense(1000, activation='relu')(x)\n",
        "x = Dense(10, activation ='softmax')(x)\n",
        "\n",
        "model = Model(mnet.input, x)\n",
        "model.compile(optimizer ='Adam', \n",
        "              loss =\"sparse_categorical_crossentropy\", \n",
        "              metrics =[\"sparse_categorical_accuracy\"]) \n",
        "\n",
        "model.fit(x_train,y_train, epochs = 5, validation_data = (x_test,y_test))\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(\"Test accuracy: {}\".format(test_accuracy))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 77s 47ms/step - loss: 1.8820 - sparse_categorical_accuracy: 0.1072 - val_loss: 1.8318 - val_sparse_categorical_accuracy: 0.1068\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 72s 46ms/step - loss: 1.7776 - sparse_categorical_accuracy: 0.1077 - val_loss: 1.7969 - val_sparse_categorical_accuracy: 0.1073\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 74s 47ms/step - loss: 1.7245 - sparse_categorical_accuracy: 0.1083 - val_loss: 1.7852 - val_sparse_categorical_accuracy: 0.1073\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 73s 47ms/step - loss: 1.6835 - sparse_categorical_accuracy: 0.1088 - val_loss: 1.7911 - val_sparse_categorical_accuracy: 0.1075\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 76s 49ms/step - loss: 1.6436 - sparse_categorical_accuracy: 0.1094 - val_loss: 1.7893 - val_sparse_categorical_accuracy: 0.1074\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 1.7893 - sparse_categorical_accuracy: 0.1074\n",
            "Test accuracy: 0.10742343962192535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qK97rABCwSa9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}